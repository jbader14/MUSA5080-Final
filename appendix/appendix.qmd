---
title: "Technical Appendix"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: show
    code_download: true
    number-sections: true
---

# Setup

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  cache = TRUE
)
```

## Load Libraries

```{r load_libraries}
# Core tidyverse
library(tidyverse)
library(janitor)
library(lubridate)

# Spatial data
library(sf)
library(tigris)

# Census data
library(tidycensus)

# Weather data
library(riem)  # For Philadelphia weather from ASOS stations

# Visualization
library(viridis)
library(grid)
library(gridExtra)
library(knitr)
library(kableExtra)

library(ggplot2)
library(scales)
library(patchwork)

# here!
library(here)

# Extra
library(tidytext)
library(MASS)

# Get rid of scientific notation. We gotta look good!
options(scipen = 999)
```

## Set Census API Key

```{r census_key}
key <- Sys.getenv("CENSUS_API_KEY")
census_api_key(key)
```

# Load Spatial and System Data
```{r load_ss_data}
# 1. Spatial Boundaries (Tracts)
tracts_sf <- tracts(state = "PA", county = "Philadelphia", year = 2021, cb = TRUE) |>
  st_transform(26918) |>
  dplyr::select(GEOID, geometry)

# 2. Bus Data by District
bus_district <- read_csv("data/Bus_Ridership_by_District.csv")

# 3. Transit Data by Mode
transit_mode <- read_csv("data/Avg_Daily_Ridership_By_Mode.csv")

# 4. Bus Shelters 
bus_shelters <- st_read("data/Bus_Shelters.geojson") |> st_transform(26918)

# 5. All Transit Stops
all_stops <- st_read("data/all_transit_stops.geojson") |>
  st_transform(26918)
```
# Load Ridership Data
```{r load_ridership_data}
# 1. Tract-Level Ridership (Raw)
bus_tract_raw <- read_csv("data/Bus_Ridership_by_Census_Tract.csv") |>
  clean_names() |>
  mutate(census_tract_id = as.character(census_tract_id))

# 2. Stop-Level Ridership (Raw List -> Combined Dataframe)
stops_files <- list.files("data", pattern = "Fall_.*\\.csv", full.names = TRUE)

# 3. Combine all bus stop files into a single df
bus_stops_raw <- stops_files |>
  map_dfr(function(file) {
    read_csv(file) |>
      mutate(year = as.integer(str_extract(file, "\\d{4}"))) |>
      clean_names() |>
      mutate(across(everything(), as.character)) 
  })
```

# Data Preprocessing and Cleaning

## Clean Ridership Data
```{r clean_ridership}
# A. Clean Tract Data
bus_tract_clean <- bus_tract_raw |>
  filter(county_name == "Philadelphia County") |>
  mutate(
    year = as.integer(str_extract(season, "\\d{4}")),
    total_ridership = on + off
  ) |>
  # Keep 2017+ for consistent analysis
  filter(year >= 2017)

# B. Clean Stop Data
bus_stops_clean <- bus_stops_raw |>
  type_convert() |> # Convert numbers back to numeric
  filter(year >= 2017) |>
  # Coalesce the mismatched column names from different years
  mutate(
    weekday_on  = coalesce(wkdy_ons, weekday_on),
    weekday_off = coalesce(wkdy_offs, weekday_of, weekday_of),
    saturday_on = coalesce(sat_ons, saturday_o),
    saturday_off = coalesce(sat_offs, saturday_1),
    sunday_on   = coalesce(sun_ons, sunday_ons),
    sunday_off  = coalesce(sun_offs, sunday_off),
    
    total_weekday = weekday_on + weekday_off
  ) |>
  # Keep only the clean columns
  dplyr::select(year, stop_code, stop_name = stop, route, total_weekday, 
         weekday_on, weekday_off, lat, lon)
```

## Filter Transit Stops (Bus vs. Rail/Trolley)
```{r clean_transit_stops}
# Define Rail/Trolley Codes to EXCLUDE
rail_codes <- c("BSL", "MFL", "HRS", "T1", "T2", "T3", "T4", "T5")

# 1. Rail Stops (for distance calc)
stops_rail <- all_stops |>
  filter(LineAbbr %in% rail_codes)

# 2. Bus Stops (Everything else, including T4 Bus, Owls, Trackless)
stops_bus <- all_stops |>
  filter(!LineAbbr %in% rail_codes)
```

# Feature Engineering

## Load Census Data
```{r load_census_data}
# ACS Demographics (2017-2021 5-Year)
acs_vars <- c(
  "B01001_001", # Total Population
  "B17001_002", # Poverty: Count below poverty level
  "B08201_002", # No Vehicle Available (Household)
  "B08201_001"  # Total Households
)

acs_data <- get_acs(
  geography = "tract", state = "PA", county = "Philadelphia",
  variables = acs_vars, year = 2021, output = "wide", geometry = FALSE
) |>
  dplyr::select(GEOID, 
         pop_total = B01001_001E,
         poverty_count = B17001_002E,
         no_vehicle_count = B08201_002E,
         hh_total = B08201_001E) |>
  mutate(
    pct_poverty = poverty_count / pop_total,
    pct_no_vehicle = no_vehicle_count / hh_total,
    across(c(pct_poverty, pct_no_vehicle), ~replace_na(., 0)) # Null handling
  )
```

## Spatial Engineering
```{r spatial_engineer}
# Count Shelters per Tract
shelters_agg <- tracts_sf |>
  st_join(bus_shelters) |>
  group_by(GEOID) |>
  summarise(n_shelters = n() - sum(is.na(objectid))) |> 
  st_drop_geometry()

# Count Bus Stops per Tract
stops_agg <- tracts_sf |>
  st_join(stops_bus) |>
  group_by(GEOID) |>
  summarise(n_stops = n()) |>
  st_drop_geometry()

# Distance to Nearest Rail Station
rail_union <- st_union(stops_rail)
tract_centroids <- st_centroid(tracts_sf)
dist_matrix <- st_distance(tract_centroids, rail_union)

dist_df <- tibble(
  GEOID = tracts_sf$GEOID,
  dist_to_rail_km = as.numeric(dist_matrix) / 1000
)
```

## Join Dataframes Together
```{r}
tract_features_static <- tracts_sf |>
  mutate(area_km2 = as.numeric(st_area(geometry)) / 1e6) |>
  st_drop_geometry() |>
  left_join(acs_data, by = "GEOID") |>
  left_join(shelters_agg, by = "GEOID") |>
  left_join(stops_agg, by = "GEOID") |>
  left_join(dist_df, by = "GEOID") |>
  mutate(
    n_stops = replace_na(n_stops, 0),
    n_shelters = replace_na(n_shelters, 0),
    stop_density = n_stops / area_km2,
    pop_density = pop_total / area_km2,
    # Equity Metric: Shelter Coverage
    pct_sheltered = ifelse(n_stops > 0, n_shelters / n_stops, 0),
    pct_sheltered = pmin(pct_sheltered, 1) # Cap at 100%
  )
```


# Exploratory Data Analysis

## Time Series Trends

### Average Daily Ridership by Mode

```{r mode_line_chart}
# Engineer a date feature for plotting
transit_mode_monthly <- transit_mode |>
  mutate(
    date = ymd(paste(Calendar_Year, Calendar_Month, "01", sep = "-"))
  )

# Plot line chart with a line for each transit mode over time
ggplot(transit_mode_monthly,
       aes(x = date,
           y = Average_Daily_Ridership,
           color = Mode)) +
  geom_line(linewidth = 1) +
  labs(
    title = "Average Daily Ridership by Transit Mode",
    subtitle = "SEPTA in Philadelphia from 2019 - 2025",
    x = "Date",
    y = "Average Daily Ridership",
    color = "Transit Mode"
  ) +
  theme_minimal()
```

### Ridership by Day of the Week

```{r ridership_dow}
# Aggregate to total ridership by year and day-of-week
bus_tract_year_dow <- bus_tract_clean |>
  group_by(year, day_of_week) |>
  summarise(
    total_ridership = sum(total_ridership, na.rm = TRUE),
    .groups = "drop"
  )

# Minimal line plot of total ridership over time by day-of-week
ggplot(bus_tract_year_dow,
       aes(x = year, y = total_ridership, color = day_of_week)) +
  geom_line(linewidth = 0.9) +
  geom_point(size = 1.8) +
  labs(
    title = "Total SEPTA Bus Ridership by Day of Week",
    subtitle = "Average daily boardings + departures for Fall only",
    x = "Year",
    y = "Total Average Daily Ridership",
    color = "Day of Week"
  ) +
  theme_minimal()

```

## Spatial Distributions

### Ridership in 2023

```{r}
# Prepare 2023 Tract Data from the CLEAN objects
ridership_2023 <- bus_tract_clean |>
  filter(day_of_week == "Weekday", year == 2023) |>
  group_by(census_tract_id) |>
  summarise(total_vol = sum(total_ridership, na.rm=TRUE))

# Join to Geometry
map_2023 <- tracts_sf |>
  left_join(ridership_2023, by = c("GEOID" = "census_tract_id")) |>
  mutate(
    # Create Quintiles
    vol_quintile = ntile(total_vol, 5),
    vol_quintile = factor(vol_quintile, labels = c("Lowest", "Low", "Med", "High", "Highest"))
  )

ggplot(map_2023) +
  geom_sf(aes(fill = vol_quintile), color = NA) +
  scale_fill_brewer(
    palette = "YlGnBu",
    na.value = "grey90",
    name = "Quintiles of Ridership"
  ) +
  labs(
    title = "Bus Ridership by Census Tract (Fall 2023)",
    subtitle = "Total Ridership = Boardings On_ + Off_",
  ) +
  theme_minimal() +
  theme(
  axis.text = element_blank(),
  axis.ticks = element_blank()
  )
```

## Equity Analysis
```{r poverty_vs_shelters}
# Join features to geometry for plotting
plot_data <- tracts_sf |>
  left_join(tract_features_static, by = "GEOID")

# Map A: Poverty
p1 <- ggplot(plot_data) +
  geom_sf(aes(fill = pct_poverty), color = NA) +
  scale_fill_viridis_c(option = "magma", labels = percent, name = "Poverty %") +
  labs(title = "Census Tract Poverty Rate (2021)", subtitle = "Where is the most financial distress?") +
  theme_void()

# Map B: Shelter Coverage
p2 <- ggplot(plot_data) +
  geom_sf(aes(fill = pct_sheltered), color = NA) +
  scale_fill_viridis_c(option = "viridis", labels = percent, name = "Sheltered %") +
  labs(title = "Percentage of Bus Stops with Shelters", subtitle = "Where are the highest % of shelters?") +
  theme_void()

# Display side-by-side
p1 + p2
```

```{r}
# Compute correlation between poverty and shelters
cor_val <- cor(tract_features_static$pct_poverty, tract_features_static$pct_sheltered, use="complete.obs")

# Plot scatterplot - No correlation
ggplot(tract_features_static, aes(x = pct_poverty, y = pct_sheltered)) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "lm", color = "red") +
  scale_x_continuous(labels = percent) +
  scale_y_continuous(labels = percent) +
  labs(title = paste0("Correlation(Poverty, Shelters): ", round(cor_val, 2)),
       subtitle = "Do poorer tracts have a smaller % of bus shelters?",
       x = "Poverty Rate", y = "Shelter Coverage")
```

##  Tract-Level Ridership Comparison (COVID Shock + Recovery)

```{r tract_perc_chg_19_21}
# 1. Prepare Data: Calculate Change for Both Periods
ridership_periods <- bus_tract_clean |>
  filter(
    year %in% c(2019, 2021, 2023),
    day_of_week == "Weekday"
  ) |>
  group_by(census_tract_id, year) |>
  summarise(total_ridership = sum(total_ridership, na.rm = TRUE), .groups = "drop") |>
  pivot_wider(
    names_from = year, 
    values_from = total_ridership, 
    names_prefix = "vol_"
  ) |>
  mutate(
    # Shock: 2019 -> 2021
    change_shock = (vol_2021 - vol_2019) / vol_2019,
    
    # Recovery: 2021 -> 2023
    change_recovery = (vol_2023 - vol_2021) / vol_2021,
    
    # Cap outliers for visualization (e.g., -100% to +100%)
    shock_capped = pmax(pmin(change_shock, 0.5), -1),
    recovery_capped = pmax(pmin(change_recovery, 1.0), -0.5)
  ) |>
  drop_na(change_shock, change_recovery)

# 2. Join to Geometry
map_periods <- tracts_sf |>
  left_join(ridership_periods, by = c("GEOID" = "census_tract_id"))

# 3. Create Plots

# Plot A: The COVID Shock (2019-2021)
p_shock <- ggplot(map_periods) +
  geom_sf(aes(fill = shock_capped), color = NA) +
  scale_fill_distiller(
    palette = "RdBu", direction = 1, 
    labels = scales::percent, 
    limits = c(-1, 0.5), # Fixed limits for comparison
    name = "Change"
  ) +
  labs(title = "The Shock (2019 → 2021)", 
       subtitle = "Ridership losses (pre-pandemic)") +
  theme_void() +
  theme(legend.position = "bottom")

# Plot B: The Recovery (2021-2023)
p_recovery <- ggplot(map_periods) +
  geom_sf(aes(fill = recovery_capped), color = NA) +
  scale_fill_distiller(
    palette = "RdBu", direction = 1, 
    labels = scales::percent,
    limits = c(-0.5, 1.0), # Different limits likely needed for recovery
    name = "Change"
  ) +
  labs(title = "The Recovery (2021 → 2023)", 
       subtitle = "Ridership gains (post-pandemic)") +
  theme_void() +
  theme(legend.position = "bottom")

# 4. Combine 
p_shock + p_recovery + 
  plot_annotation(
    title = "SEPTA Demand Resilience: Shock vs. Recovery",
    subtitle = "Comparing the spatial patterns of gains/losses due to the COVID pandemic",
    theme = theme(plot.title = element_text(size = 16, face = "bold"))
  )
```

## Fishnet Grid: Ridership + Bus Stops
```{r fishnet}
# 4. Fishnet Analysis (Stop Density & Weekday Ridership)

# 1. Prepare 2023 Data (Weekday Only)
stops_2023_sf <- bus_stops_clean |>
  filter(year == 2023) |>
  st_as_sf(coords = c("lon", "lat"), crs = 4326) |>
  st_transform(26918)

# 2. Create Fishnet Grid (500m)
# Use the union of tracts to define the city boundary
philly_boundary <- st_union(tracts_sf)

fishnet <- st_make_grid(
  philly_boundary,
  cellsize = 500, # 500m x 500m
  square = TRUE
) |>
  st_as_sf() |>
  mutate(grid_id = row_number())

# Clip grid to city shape (optional, makes map cleaner)
fishnet <- fishnet[philly_boundary, ]

# 3. Aggregate Stops to Grid
# Spatial join: Assign grid_id to each stop
stops_joined <- st_join(stops_2023_sf, fishnet, join = st_within)

# Summarize data by grid cell
fishnet_agg <- stops_joined |>
  st_drop_geometry() |> 
  group_by(grid_id) |>
  summarise(
    countStops = n(),
    totalRid = sum(total_weekday, na.rm = TRUE),
    .groups = "drop"
  )

# Join back to grid geometry for plotting
fishnet_plot_data <- fishnet |>
  left_join(fishnet_agg, by = "grid_id") |>
  # Replace NAs with 0 so empty cells plot as "0" instead of gray/missing
  mutate(
    countStops = replace_na(countStops, 0),
    totalRid   = replace_na(totalRid, 0)
  )

# 4. Plotting

# Plot A: Ridership Intensity
p_rid <- ggplot() +
  geom_sf(data = fishnet_plot_data, aes(fill = totalRid), color = NA) +
  geom_sf(data = philly_boundary, fill = NA, color = "white", size = 0.5) +
  scale_fill_viridis_c(
    name = "Weekday\nRidership",
    trans = "sqrt",
    option = "plasma"
  ) +
  labs(
    title = "Ridership Density",
    subtitle = "500m Grid, Fall 2023"
  ) +
  theme_void()

# Plot B: Stop Density
p_stops <- ggplot() +
  geom_sf(data = fishnet_plot_data, aes(fill = countStops), color = NA) +
  geom_sf(data = philly_boundary, fill = NA, color = "white", size = 0.5) +
  scale_fill_viridis_c(
    name = "Stop Count",
    trans = "sqrt",
    option = "viridis"
  ) +
  labs(
    title = "Stop Density",
    subtitle = "500m Grid, Fall 2023"
  ) +
  theme_void()

# Display side-by-side
p_rid + p_stops + 
  plot_annotation(
    title = "Comparison of Daily Weekday Ridership and Bus Stop Densities",
    theme = theme(plot.title = element_text(size = 16, face = "bold"))
  )
```

# Model Building Workflow

## Setup

```{r}
# 1. Prepare Longitudinal Panel (2017-2023)
# Aggregate ridership to one row per Tract-Year (Weekdays only)
bus_panel <- bus_tract_clean |>
  filter(day_of_week == "Weekday") |>
  group_by(census_tract_id, census_tract_name, year) |>
  summarise(total_ridership = sum(total_ridership, na.rm=TRUE), .groups="drop")

# 2. Join with Static Features (Demographics, Shelters, Rail Dist)
model_data <- bus_panel |>
  left_join(tract_features_static, by = c("census_tract_id" = "GEOID")) |>
  st_drop_geometry() |> # Drop geometry
  mutate(
    # Time Trends
    trend = year - min(year),
    post_covid = if_else(year >= 2021, 1, 0),
    
    # Log Transformations (handling zeros for density vars)
    log_pop_density = log(pop_density + 1),
    log_stop_density = log(stop_density + 1)
  ) |>
  filter(!is.na(total_ridership))
```

```{r}
# 1. Define Error Metric
mae <- function(obs, pred) mean(abs(obs - pred))

# 2. Train/Test Split

# TRAIN = pre-COVID + two recovery year (2017-19, 2021-2022)
tract_train <- model_data |>
  filter(year != 2023) |>
  mutate(census_tract_id = as.factor(census_tract_id))

# TEST = heldout, evaluation year (2023)
tract_test <- model_data |>
  filter(year == 2023) |>
  mutate(census_tract_id = as.factor(census_tract_id))
```

## Baseline Model 1: Trend + COVID + Tract FE

```{r model_1}
# A. Fit Poisson
m1_pois <- glm(
  total_ridership ~ trend + post_covid + census_tract_id,
  data = tract_train,
  family = "poisson"
)

# B. Check Dispersion
dispersion <- sum(residuals(m1_pois, type = "pearson")^2) / m1_pois$df.residual

cat("Dispersion Parameter:", round(dispersion, 2), "\n")
if(dispersion > 1.5) cat("⚠️ Overdispersion detected! Switching to Negative Binomial.\n")

# C. Fit Negative Binomial (The Real Baseline)
m1_nb <- glm.nb(
  total_ridership ~ trend + post_covid + census_tract_id,
  data = tract_train
)

# D. Evaluate
pred_m1 <- predict(m1_nb, newdata = tract_test, type = "response")
mae_m1  <- mae(tract_test$total_ridership, pred_m1)

cat("Baseline (M1) MAE:", round(mae_m1, 2))
```

## Model 2: Trend + COVID + Infrastructure + Equity

```{r model_2}
# Fit Model: Demographics + Infrastructure (No Tract FE)
m2_nb <- glm.nb(
  total_ridership ~ 
    trend + post_covid + 
    # Infrastructure Features
    stop_density + dist_to_rail_km + pct_sheltered +
    # Demographic Features
    pct_poverty + pct_no_vehicle + pop_density,
  data = tract_train
)

# Evaluate
pred_m2 <- predict(m2_nb, newdata = tract_test, type = "response")
mae_m2  <- mae(tract_test$total_ridership, pred_m2)

# Print Policy Findings
cat("M2 Equity + Infrastructure (No FE) MAE:", round(mae_m2, 2), "\n")
```

## Model 3: Trend + COVID + FE + COVID Interactions with Infrastructure/Equity
```{r model_3}
m3_nb <- glm.nb(
  total_ridership ~ 
    # 1. Global Trends
    trend + post_covid + 
    
    # 2. Differential Recovery (Interactions)
    # "Did high-poverty or sheltered areas recover differently?"
    post_covid:pct_poverty +
    post_covid:pct_sheltered +
    post_covid:dist_to_rail_km +
    
    # 3. Local Baselines (Fixed Effects)
    census_tract_id,
  data = tract_train
)

# Evaluate
pred_m3 <- predict(m3_nb, newdata = tract_test, type = "response")
mae_m3  <- mae(tract_test$total_ridership, pred_m3)

cat("M3 FE + Interactions MAE:", round(mae_m3, 2))
```

## Model Performance Comparison
```{r}
results <- tibble(
  Model = c("M1: Baseline (FE)", "M2: Equity + Infrastructure", "M3: Final (FE + Interactions)"),
  MAE = c(mae_m1, mae_m2, mae_m3),
  Interpretation = c(
    "Controls for local history only.",
    "Tests policy variables (Shelters/Poverty).",
    "Combines Local history + Equity-driven recovery."
  )
)

kable(results, digits = 2) |>
  kable_styling(bootstrap_options = "striped", full_width = F)
```


